{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bb4d8b2-228a-48f8-96a8-8591cc520a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "import ast\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import pypdfium2 as pdfium\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key = os.getenv('OPEN_AI_KEY'))\n",
    "with open(os.path.join(os.getcwd(), 'prompt_8names.txt'), 'r') as f:\n",
    "    prompt_txt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5472b013-b73a-43e5-8f68-c6ac08dadef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "import ast\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import pypdfium2 as pdfium\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from openai import OpenAI\n",
    "\n",
    "# read api key from env file\n",
    "client = OpenAI(api_key = os.getenv('OPEN_AI_KEY'))\n",
    "\n",
    "# please place the correct path of prompt txt file\n",
    "with open(os.path.join(os.getcwd(), 'prompt_9_dropdown.txt'), 'r') as f:\n",
    "    prompt_txt = f.read()\n",
    "    \n",
    "def encode_page(image):\n",
    "    '''\n",
    "    Converts the image of a page to a base64 string\n",
    "    Input: PIL image\n",
    "    '''\n",
    "    # create an in memory buffer\n",
    "    buffered = BytesIO()\n",
    "    # save the input PIL image in the buffer as a png file.\n",
    "    image.save(buffered, format=\"png\")\n",
    "    # convert the png file to base64 string\n",
    "    img_base64_str = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "    \n",
    "    return img_base64_str\n",
    "\n",
    "def parse_pdf_fetch_img(pdf_path, page_num):\n",
    "    '''\n",
    "    Given a path of the pdf (Datasheet) and a page number, this function extracts that particular page and scales it 3 times and returns.\n",
    "    Input: pdf_path, page_num\n",
    "    '''\n",
    "    # Read the pdf file from the path\n",
    "    pdf = pdfium.PdfDocument(pdf_path)\n",
    "    # Get the page object from the pdf object\n",
    "    page = pdf[page_num]\n",
    "\n",
    "    # Convert page object to PIL image and scale it 3 times.\n",
    "    img = page.render_topil(\n",
    "        scale = 3,\n",
    "        rotation = 0,\n",
    "        crop = (0, 0, 0, 0),\n",
    "        greyscale = False,\n",
    "        optimise_mode  = pdfium.OptimiseMode.NONE\n",
    "    )\n",
    "    return img\n",
    "\n",
    "def call_openai_model(content_payload):\n",
    "    '''\n",
    "    Given the content, this function fetches the response from the OpenAI api endpoint. \n",
    "    The content from the response is either converted to a JSON or a JSON string.\n",
    "    Input: content_payload (contains prompt and base64 image)\n",
    "    '''    \n",
    "    # create headers\n",
    "    headers = {\n",
    "      \"Content-Type\": \"application/json\",\n",
    "      \"Authorization\": f\"Bearer {os.getenv('OPEN_AI_KEY')}\"\n",
    "    }\n",
    "\n",
    "    # initialise payload and set paramas\n",
    "    payload = {\n",
    "    \"model\": \"gpt-4o\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": content_payload\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 1024,\n",
    "    \"temperature\": 0.01\n",
    "    }\n",
    "\n",
    "    # get the response\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "    # extract the content and convert it to json or json string\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            # evaluate the json string and convert the string to json\n",
    "            response_json = ast.literal_eval(response.json()['choices'][0]['message']['content'].replace(\"```\", \"\").replace(\"json\",\"\"))\n",
    "            return response_json\n",
    "        except Exception as e:\n",
    "            # return json string\n",
    "            return response.json()['choices'][0]['message']['content'].replace(\"```\", \"\").replace(\"json\",\"\")  \n",
    "    elif response.status_code == 429:\n",
    "        print(f\"Rate limit reached{response.status_code}\")\n",
    "        time.sleep(20)  # 20 seconds sleep\n",
    "    elif response.status_code == 500:\n",
    "        print(\"Issue in request..\")\n",
    "    else:\n",
    "        pass \n",
    "\n",
    "def fetch_attribute_json(model_num, pdf_path, page_num):\n",
    "    '''\n",
    "    Given the path of the datasheet pdf, and the page number in which the order info table is present,\n",
    "    this method uses all the other methods to extract the page as an image from the pdf and, adds the model number to the prompt,\n",
    "    and calls and fetches the response from the OpenAI endpoint.\n",
    "    '''    \n",
    "    # extract page image from the datasheet\n",
    "    page_img = parse_pdf_fetch_img(pdf_path, page_num)\n",
    "    # get the base64 of the page image\n",
    "    base64_img = encode_page(page_img)\n",
    "    # add model number to the prompt\n",
    "    openai_prompt =  prompt_txt + model_num\n",
    "\n",
    "    # create content payload\n",
    "    common_prompt_content = { \"type\": \"text\", \"text\": openai_prompt }\n",
    "    content_payload_ = []  \n",
    "    content_payload_.append(common_prompt_content)\n",
    "\n",
    "    # create base64 template\n",
    "    base64_content_template = { \n",
    "        \"type\": \"image_url\", \n",
    "        \"image_url\": {\n",
    "                \"url\": f\"data:image/png;base64,{base64_img}\",\n",
    "                \"detail\": \"high\"\n",
    "                }\n",
    "    }\n",
    "    \n",
    "    content_payload_.append(base64_content_template)\n",
    "    \n",
    "    # fetch the response\n",
    "    resp = call_openai_model(content_payload_)\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3143e2e9-dfdc-422b-845d-3ddb3274ab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = 'GALN-SA4C-740-U-T4FT-WM-XX'\n",
    "pdf_path = '/home/sriteja-code/info_table_extraction/1.pdf'\n",
    "page_num = 1\n",
    "x = fetch_attribute_json(model_num, pdf_path, page_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a257cb7a-0c85-41af-ba0c-da0a3ffe02b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Series Name': {'GALN': 'GALN'},\n",
       "  'CCT': {'40': '4000K'},\n",
       "  'CRI': {'7': '70'},\n",
       "  'Voltage': {'U': 'Universal (120-277V)'},\n",
       "  'Lumens': None,\n",
       "  'Environment': None,\n",
       "  'Mounting': {'WM': 'Wall Mount'},\n",
       "  'Dimming Protocol': None},\n",
       " dict)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c801382d-b2e3-4d4a-a60d-03dffb19eeae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
